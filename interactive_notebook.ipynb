{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "330_project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rKXkT1-QbIw9",
        "DjbtWrsihow6",
        "TZcm5YIlbyvP",
        "ChlsaYSYb5-m"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "23e7c331c9f4424b9f0a52ddb21fda40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee31828abfa34acdbe972f40aaa31b94",
              "IPY_MODEL_4aeee22b18dc46c495aca47f52a57291"
            ],
            "layout": "IPY_MODEL_0068cad980e544e4a3825ecef04f61ee"
          }
        },
        "ee31828abfa34acdbe972f40aaa31b94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "  0%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abdc093d3edc4071adf210adbda9c8b4",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3c75824f28b49bab470f2cebce902a4",
            "value": 0
          }
        },
        "4aeee22b18dc46c495aca47f52a57291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ce8ec29b49a4eb595789140192e8078",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8b51560feda4421394c7b52200d9d397",
            "value": " 0/10000 [00:00&lt;?, ?it/s]"
          }
        },
        "0068cad980e544e4a3825ecef04f61ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abdc093d3edc4071adf210adbda9c8b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3c75824f28b49bab470f2cebce902a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "3ce8ec29b49a4eb595789140192e8078": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b51560feda4421394c7b52200d9d397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKXkT1-QbIw9"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWEtwIXShZVD",
        "outputId": "04292ad9-e486-4ab2-af78-26a9bea3f578"
      },
      "source": [
        "!pip install gpytorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gpytorch in /usr/local/lib/python3.6/dist-packages (1.2.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "yk-kpcanr4Jq"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import gpytorch\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tqdm.notebook as tqdm\n",
        "sns.set_style('darkgrid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV1yiZ5YhbtZ"
      },
      "source": [
        "device = torch.device('cuda:0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3mulf6mbQAC"
      },
      "source": [
        "#Environments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "Sa_sBuMBr4J8"
      },
      "source": [
        "def default_transform(x):\n",
        "    '''Function to squash and transform last dimension of x.'''\n",
        "    return torch.sum(x, dim=-1)\n",
        "\n",
        "clamp_val = 100\n",
        "\n",
        "def csc_tranform(x):\n",
        "    return torch.sum(1 / torch.sin(x), dim=-1).clamp(min=-clamp_val, max=clamp_val)\n",
        "\n",
        "def tan_transform(x):\n",
        "    return torch.sum(torch.tan(x), dim=-1).clamp(min=-clamp_val, max=clamp_val)\n",
        "\n",
        "def atan_transform(x):\n",
        "    return torch.sum(torch.atan(1 / x), dim=-1)\n",
        "\n",
        "def sin_inv_transform(x):\n",
        "    return torch.sum(torch.sin(1 / x), dim=-1)\n",
        "\n",
        "def sum_square_transform(x):\n",
        "    return torch.sum(x.pow(2), dim=-1)\n",
        "\n",
        "def square_sum_transform(x):\n",
        "    return torch.sum(x, dim=-1).pow(2)\n",
        "\n",
        "def sum_sin_transform(x):\n",
        "    return torch.sum(torch.sin(x), dim=-1)\n",
        "\n",
        "def prod_transform(x):\n",
        "    return torch.prod(x, dim=-1)\n",
        "\n",
        "def sign_transform(x):\n",
        "    return torch.prod(torch.sign(x), dim=-1)\n",
        "\n",
        "def sum_floor_transform(x):\n",
        "    return 5 * torch.sum(torch.floor(x), dim=-1)\n",
        "\n",
        "def noisy_sum_floor_transform(x):\n",
        "    mean = 10 * torch.sum(torch.floor(x), dim=-1)\n",
        "    noise = torch.normal(torch.zeros(mean.shape), torch.ones(mean.shape)).to(x.device)\n",
        "    return noise + mean \n",
        "\n",
        "class FunctionTaskGenerator(nn.Module):\n",
        "    def __init__(self, input_dim=1, latent_dim=1, lengthscale=0.5, transform=default_transform, train_size=None):\n",
        "        '''Define distribution F over regression tasks. A task f~F is a function \n",
        "        f(X) = transform(Z) where Z~GP(X) is sampled from a multitask GP using \n",
        "        an RBF kernel with latent_dim tasks and transform is an arbitrary map.\n",
        "        '''\n",
        "        super().__init__()\n",
        "        self.mean_module = gpytorch.means.MultitaskMean(\n",
        "            gpytorch.means.ConstantMean(), num_tasks=latent_dim\n",
        "        )\n",
        "        rbf = gpytorch.kernels.RBFKernel()\n",
        "        rbf.raw_lengthscale.data[...] = lengthscale\n",
        "        self.covar_module = gpytorch.kernels.MultitaskKernel(\n",
        "            rbf, num_tasks=latent_dim, rank=1\n",
        "        )\n",
        "        self.transform = transform\n",
        "        self.input_dim = input_dim\n",
        "        self.dummy = nn.Parameter(torch.empty([]))\n",
        "    \n",
        "    def forward(self, batch, K=5, validation=False):\n",
        "        '''Samples batch of regression tasks with K examples per task. \n",
        "        Returns:\n",
        "        X: datapoints sampled from N(0, I) for batch of tasks \n",
        "            with shape [batch, K, input_dim]\n",
        "        Y: labels f(X) for f~F for batch of tasks with shape [batch, K]\n",
        "        '''\n",
        "        shape = [batch, K, self.input_dim]\n",
        "        with torch.no_grad():\n",
        "            X = torch.normal(torch.zeros(shape), torch.ones(shape)).to(self.dummy.device)\n",
        "            Z = gpytorch.distributions.MultitaskMultivariateNormal(\n",
        "                self.mean_module(X), self.covar_module(X)\n",
        "            ).sample()\n",
        "            Y = self.transform(Z)\n",
        "            assert Y.dim() == 2\n",
        "        return X, Y\n",
        "\n",
        "\n",
        "class SinusoidTaskGenerator(nn.Module):\n",
        "    def __init__(self, a_min=0.1, a_max=5.0, p_min=0.0, p_max=2*np.pi, f_min=0.5, f_max=2.0, \n",
        "                 tr_min=-5.0, tr_max=5.0, te_min=-5.0, te_max=10.0, noise=0.01, \n",
        "                 transform=torch.sin, out_of_range_val=False):\n",
        "        '''Define distribution parameters for sinusoidal regression task.'''\n",
        "        super().__init__()\n",
        "        self.amp_range = [a_min, a_max]             # DKT: [0.1, 5.0], BMAML: [0.1, 5.0]\n",
        "        self.phase_range = [p_min, p_max]           # DKT: [0.1, pi], BMAML: [0.0, 2*pi]\n",
        "        self.freq_range = [f_min, f_max]            # DKT: [1.0, 1.0] (unused), BMAML: [0.5, 2.0]\n",
        "        self.train_samp_range = [tr_min, tr_max]    # DKT: [-5.0, 5.0], BMAML: [-5.0, 5.0]\n",
        "        self.test_samp_range = [te_min, te_max]     # DKT: Used for out-of-range testing, if needed\n",
        "        self.noise_var = noise                      # DKT: 0.0 (unused), BMAML: 0.01.\n",
        "        self.input_dim = 1\n",
        "        self.transform = transform\n",
        "        self.out_of_range_val = out_of_range_val\n",
        "        self.dummy = nn.Parameter(torch.empty([]))\n",
        "    \n",
        "    def forward(self, batch, K, validation=False):\n",
        "        '''Samples batch of sinusoidal regression tasks with K examples per task.\n",
        "        Returns:\n",
        "        X: datapoints of shape (batch, support_size+query_size), sampled uniformly from \n",
        "            self.train_samp_range/self.test_samp_range\n",
        "        Y: Labels for these datapoints of X, aka Y[i][j] = A_i*np.sin(X[i][j] + C_i) for all (i, j).\n",
        "            A_i is the amplitude for the i-th task, sampled uniformly from self.amplitude_range\n",
        "            C_i is the phase for the i-th task, sampled uniformly from self.phase_range\n",
        "        '''\n",
        "        amp = torch.empty(batch).uniform_(*self.amp_range)\n",
        "        phase = torch.empty(batch).uniform_(*self.phase_range)\n",
        "        freq = torch.empty(batch).uniform_(*self.freq_range)\n",
        "        shape = [batch, K]\n",
        "        noise = torch.normal(torch.zeros(shape), self.noise_var * amp[:, None].expand(shape))\n",
        "        with torch.no_grad():\n",
        "            samp_range = self.test_samp_range if (self.out_of_range_val and validation) else self.train_samp_range\n",
        "            X = torch.empty(shape).uniform_(*samp_range)\n",
        "            Y = amp[:, None] * self.transform(freq[:, None] * X + phase[:, None]) + noise    \n",
        "        return X.unsqueeze(-1).to(self.dummy.device), Y.to(self.dummy.device)\n",
        "\n",
        "\n",
        "class StepFunctionTaskGenerator(nn.Module):\n",
        "    def __init__(self, s_min=-2.5, s_max=2.5, samp_min=-5.0, samp_max=5.0, noise=0.03):\n",
        "        '''Define distribution parameters for step function task.'''\n",
        "        super().__init__()\n",
        "        self.switch_range = [s_min, s_max]\n",
        "        self.samp_range = [samp_min, samp_max]\n",
        "        self.noise = noise\n",
        "        self.input_dim = 1\n",
        "        self.dummy = nn.Parameter(torch.empty([]))\n",
        "\n",
        "    def forward(self, batch, K, validation=False):\n",
        "        '''Samples batch of step function tasks.'''\n",
        "        switches = torch.empty((batch, 3)).uniform_(*self.switch_range)\n",
        "        print(\"Switches:\", switches)\n",
        "        shape = [batch, K]\n",
        "        noise = torch.normal(torch.zeros(shape), self.noise)\n",
        "        with torch.no_grad():\n",
        "            X = torch.empty(shape).uniform_(*self.samp_range)\n",
        "            num_greater = torch.sum(X[:, :, None] > switches[:, None, :], dim=2)\n",
        "            Y = 2 * (num_greater % 2) - 1 + noise\n",
        "        return X.unsqueeze(-1).to(self.dummy.device), Y.to(self.dummy.device)\n",
        "\n",
        "\n",
        "class ConstantTaskGenerator(nn.Module):\n",
        "    def __init__(self, input_dim=2):\n",
        "        '''Define distribution F over trivial constant regression tasks.'''\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.dummy = nn.Parameter(torch.empty([]))\n",
        "  \n",
        "    def forward(self, batch, K=5, validation=False):\n",
        "      '''Samples batch of regression tasks with K examples per task. \n",
        "      Returns:\n",
        "      X: datapoints sampled from N(0, I) for batch of tasks \n",
        "          with shape [batch, K, input_dim]\n",
        "      Y: labels f(X) for f~F for batch of tasks with shape [batch, K]\n",
        "      '''\n",
        "      shape = [batch, K, self.input_dim]\n",
        "      with torch.no_grad():\n",
        "          X = torch.normal(torch.zeros(shape), torch.ones(shape)).to(self.dummy.device)\n",
        "          Y = torch.rand([batch, 1]).to(self.dummy.device).expand(-1, K)\n",
        "      return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HitNZ6hCbpyB"
      },
      "source": [
        "#Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjbtWrsihow6"
      },
      "source": [
        "## Basic Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "N9Ej2UN4nZae"
      },
      "source": [
        "class FunctionPriorModel(gpytorch.models.ExactGP):\n",
        "    '''Exact GP model.'''\n",
        "    def __init__(self, likelihood):\n",
        "        super().__init__(None, None, likelihood)\n",
        "        self.mean_module = gpytorch.means.ConstantMean()\n",
        "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = self.mean_module(x)\n",
        "        covar = self.covar_module(x)\n",
        "        return gpytorch.distributions.MultivariateNormal(mean, covar)\n",
        "    \n",
        "    def clear(self):\n",
        "        self.train_inputs = None\n",
        "        self.train_targets = None\n",
        "\n",
        "class LinearRegression(gpytorch.models.ExactGP):\n",
        "    '''Bayesian linear regression model.'''\n",
        "    def __init__(self, likelihood, input_dim):\n",
        "        super().__init__(None, None, likelihood)\n",
        "        self.mean_module = gpytorch.means.LinearMean(input_dim)\n",
        "        self.covar_module = gpytorch.kernels.LinearKernel()\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = self.mean_module(x)\n",
        "        covar = self.covar_module(x)\n",
        "        return gpytorch.distributions.MultivariateNormal(mean, covar)\n",
        "    \n",
        "    def clear(self):\n",
        "        self.train_inputs = None\n",
        "        self.train_targets = None\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    '''Simple multilayer perceptron with relu activations and batchnorm.'''\n",
        "    def __init__(self, input_units, hidden_units, output_units, hidden_layers):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        units = input_units\n",
        "        for i in range(hidden_layers):\n",
        "            self.layers.extend([\n",
        "                nn.Linear(units, hidden_units),\n",
        "                nn.BatchNorm1d(hidden_units),\n",
        "                nn.ReLU(),\n",
        "            ])\n",
        "            units = hidden_units\n",
        "        self.layers.extend([\n",
        "            nn.Linear(units, output_units),\n",
        "            nn.BatchNorm1d(output_units),\n",
        "        ])\n",
        "        \n",
        "    def forward(self, x):\n",
        "        batch_shape = x.shape[:-1]\n",
        "        x = x.flatten(end_dim=-2)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x.reshape(*batch_shape, -1)\n",
        "        \n",
        "class LatentPriorModel(gpytorch.models.ExactGP):\n",
        "    '''Exact multitask GP model. Optionally uses provided deep kernel model.'''\n",
        "    def __init__(self, likelihood, output_dim, deep_kernel=None):\n",
        "        super().__init__(None, None, likelihood)\n",
        "        self.mean_module = gpytorch.means.MultitaskMean(\n",
        "            gpytorch.means.ConstantMean(), num_tasks=output_dim\n",
        "        )\n",
        "        self.covar_module = gpytorch.kernels.MultitaskKernel(\n",
        "            gpytorch.kernels.RBFKernel(), num_tasks=output_dim, rank=1\n",
        "        )\n",
        "        self.deep_kernel = deep_kernel\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.deep_kernel is not None:\n",
        "            x = self.deep_kernel(x)\n",
        "        mean = self.mean_module(x)\n",
        "        covar = self.covar_module(x)\n",
        "        return gpytorch.distributions.MultitaskMultivariateNormal(mean, covar)\n",
        "    \n",
        "    def clear(self):\n",
        "        self.train_inputs = None\n",
        "        self.train_targets = None\n",
        "\n",
        "class VariationalModel(gpytorch.models.ExactGP):\n",
        "    '''Multitask variational posterior model that uses deep kernel\n",
        "    and mean functions.\n",
        "    '''\n",
        "    def __init__(self, likelihood, input_dim, latent_dim, hidden_units, hidden_layers):\n",
        "        super().__init__(None, None, likelihood)\n",
        "        self.covar_module = gpytorch.kernels.MultitaskKernel(\n",
        "            gpytorch.kernels.RBFKernel(), num_tasks=latent_dim, rank=1\n",
        "        )\n",
        "        self.input_dim = input_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.mlp = MLP(input_dim + 1, hidden_units, input_dim + latent_dim, hidden_layers)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        inputs = torch.cat([x] + [y.unsqueeze(-1)], dim=-1)\n",
        "        outputs = self.mlp(inputs)\n",
        "        mean = outputs[..., :self.latent_dim]\n",
        "        embedding = outputs[..., self.latent_dim:]\n",
        "        assert embedding.size(-1) == self.input_dim\n",
        "        covar = self.covar_module(embedding)\n",
        "        return gpytorch.distributions.MultitaskMultivariateNormal(mean, covar)\n",
        "    \n",
        "    def clear(self):\n",
        "        self.train_inputs = None\n",
        "        self.train_targets = None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZcm5YIlbyvP"
      },
      "source": [
        "## VMGP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "W-Qk49S4r4KC"
      },
      "source": [
        "class VariationalMetaGP(nn.Module):\n",
        "    '''Variational GP meta-learner with deep non-Gaussian likelihood.\n",
        "    out_var: downweighting of the KL-divergence term in the loss; represents\n",
        "      the variance of the Gaussians in the mixture representing the model's\n",
        "      posterior predictions\n",
        "    deep_kernel_dim: (optional int): if set, use a deep kernel for the \n",
        "      latent prior p(z|x) represented as a learned projection from input_dim to\n",
        "      deep_kernel_dim composed with an RBF kernel.\n",
        "    '''\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim,\n",
        "        hidden_units,\n",
        "        latent_dim,\n",
        "        hidden_layers,\n",
        "        out_var,\n",
        "        deep_kernel_dim=None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        if deep_kernel_dim is None:\n",
        "            kernel_dim = input_dim\n",
        "            self.deep_kernel = None\n",
        "        else:\n",
        "            kernel_dim = deep_kernel_dim\n",
        "            self.deep_kernel = MLP(input_dim, hidden_units, kernel_dim, hidden_layers)\n",
        "        self.variational_posterior = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=latent_dim)\n",
        "        self.variational_model = VariationalModel(\n",
        "            self.variational_posterior, input_dim, latent_dim, hidden_units, hidden_layers\n",
        "        )\n",
        "        self.latent_prior = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=latent_dim)\n",
        "        self.latent_prior_model = LatentPriorModel(self.latent_prior, latent_dim, self.deep_kernel)\n",
        "        self.likelihood_transform = MLP(latent_dim, hidden_units, 1, hidden_layers)\n",
        "        self.latent_dim = latent_dim\n",
        "        self.out_var = out_var\n",
        "        \n",
        "    def loss(self, X, Y):\n",
        "        '''Compute loss over batch of tasks with datapoints X and labels Y.\n",
        "        Returns the ELBO loss across all tasks.\n",
        "        '''\n",
        "        self.train()\n",
        "        assert Y.dim() == X.dim() - 1\n",
        "        self.latent_prior_model.eval()\n",
        "        self.variational_model.eval()\n",
        "        p_Z_X = self.latent_prior(self.latent_prior_model(X))\n",
        "        q_Z_Y = self.variational_posterior(self.variational_model(X, Y))\n",
        "        Z_samp = q_Z_Y.rsample()\n",
        "        Y_pred = self.likelihood_transform(Z_samp).squeeze(-1)\n",
        "        log_p_Y_Z_samp = -torch.pow(Y_pred - Y, 2).sum()\n",
        "        dkl = torch.distributions.kl.kl_divergence(q_Z_Y, p_Z_X).sum()\n",
        "        ELBO = log_p_Y_Z_samp - self.out_var * dkl\n",
        "        return -ELBO\n",
        "\n",
        "    def forward(self, X_train, Y_train, X_test, samples=100):\n",
        "        '''Evaluate model predictions on a single meta-test task.\n",
        "        Takes D_train = (X_train, Y_train) and returns the predicted Y_test \n",
        "        corresponding to X_test (in the form of samples from the prediction\n",
        "        distribution along dimension 0 of the returned tensor).\n",
        "        '''\n",
        "        assert X_train.dim() == 2\n",
        "        self.eval()\n",
        "        Z_samp = self.variational_posterior(\n",
        "            self.variational_model(X_train, Y_train)\n",
        "        ).sample(sample_shape=torch.Size([samples]))\n",
        "        Y_pred_all = []\n",
        "\n",
        "        for Z_task_samp in Z_samp:\n",
        "            self.latent_prior_model.set_train_data(X_train, Z_task_samp, strict=False)\n",
        "            Z_test = self.latent_prior(self.latent_prior_model(X_test)).sample()\n",
        "            Y_pred = self.likelihood_transform(Z_test).squeeze(-1)\n",
        "            Y_pred_all.append(Y_pred)\n",
        "            self.latent_prior_model.clear()\n",
        "        \n",
        "        return torch.stack(Y_pred_all).detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChlsaYSYb5-m"
      },
      "source": [
        "## MGP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "tnVYRwYLM425"
      },
      "source": [
        "class MetaGP(nn.Module):\n",
        "    '''Baseline non-variational GP meta-learner.\n",
        "    deep_kernel_dim: (optional int): if set, use a deep kernel for the \n",
        "      latent prior p(z|x) represented as a learned projection from input_dim to\n",
        "      deep_kernel_dim composed with an RBF kernel.\n",
        "    '''\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim,\n",
        "        deep_kernel_dim=None,\n",
        "        hidden_units=None,\n",
        "        hidden_layers=None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
        "        self.gp = FunctionPriorModel(self.likelihood)\n",
        "        self.mll = gpytorch.mlls.ExactMarginalLogLikelihood(self.likelihood, self.gp)\n",
        "        self.deep_kernel = (\n",
        "            MLP(input_dim, hidden_units, deep_kernel_dim, hidden_layers)\n",
        "            if deep_kernel_dim is not None\n",
        "            else None\n",
        "        )\n",
        "        \n",
        "    def loss(self, X, Y):\n",
        "        '''Compute meta loss over batch of tasks with datapoints X and labels Y.\n",
        "        Returns negative marginal log likelihood across all tasks.\n",
        "        '''\n",
        "        self.train()\n",
        "        self.gp.eval()\n",
        "        if self.deep_kernel is not None:\n",
        "            X = self.deep_kernel(X)\n",
        "        pred_loss = 0\n",
        "        p_Y_X = self.gp(X)\n",
        "        loss = -self.mll(p_Y_X, Y)\n",
        "        return loss.sum()\n",
        "\n",
        "    def forward(self, X_train, Y_train, X_test, samples=100):\n",
        "        '''Evaluate model predictions on a single meta-test task.\n",
        "        Takes D_train = (X_train, Y_train) and returns the predicted Y_test \n",
        "        corresponding to X_test.\n",
        "        '''\n",
        "        assert X_train.dim() == 2\n",
        "        self.eval()\n",
        "        if self.deep_kernel is not None:\n",
        "            X_train = self.deep_kernel(X_train)\n",
        "            X_test = self.deep_kernel(X_test)\n",
        "        self.gp.set_train_data(X_train, Y_train, strict=False)\n",
        "        Y_pred = self.likelihood(self.gp(X_test)).sample(sample_shape=torch.Size([samples]))\n",
        "        self.gp.clear()\n",
        "        return Y_pred.detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7dvptJTFova"
      },
      "source": [
        "## Baseline Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ilbm6khFXpI"
      },
      "source": [
        "class FunctionalMLP(nn.Module):\n",
        "    '''Simple multilayer perceptron, allowing functional passing of parameters.'''\n",
        "    def __init__(self, input_units, hidden_units, output_units, hidden_layers):\n",
        "        super().__init__()\n",
        "        self.weights = nn.ParameterList()\n",
        "        self.biases = nn.ParameterList()\n",
        "        units = input_units\n",
        "        for i in range(hidden_layers):\n",
        "            self.weights.append(nn.Parameter(\n",
        "                torch.empty([units, hidden_units])\n",
        "            ))\n",
        "            self.biases.append(nn.Parameter(\n",
        "                torch.zeros([hidden_units])\n",
        "            ))\n",
        "            units = hidden_units\n",
        "        self.weights.append(nn.Parameter(\n",
        "            torch.empty([units, output_units])\n",
        "        ))\n",
        "        self.biases.append(nn.Parameter(\n",
        "            torch.zeros([output_units])\n",
        "        ))\n",
        "        for weight in self.weights:\n",
        "            nn.init.xavier_uniform_(weight)\n",
        "        \n",
        "    def forward(self, x, params=None):\n",
        "        batch_shape = x.shape[:-1]\n",
        "        x = x.flatten(end_dim=-2)\n",
        "        \n",
        "        if params is None:\n",
        "            params = list(self.parameters())\n",
        "\n",
        "        weights = params[:len(params) // 2]\n",
        "        biases = params[len(params) // 2:]\n",
        "        \n",
        "        for i, (weight, bias) in enumerate(zip(weights, biases)):\n",
        "            x = x @ weight + bias\n",
        "            if i < len(weights) - 1:\n",
        "                x = F.relu(x)\n",
        "\n",
        "        return x.reshape(*batch_shape, -1)\n",
        "\n",
        "class EMAML(nn.Module):\n",
        "    '''An ensemble of MAMLs. Can view predictions of ensembles as samples from predictive posterior.'''\n",
        "    def __init__(self, support_size, query_size, input_dim, hidden_units, hidden_layers, num_mamls=20, inner_lr=0.1):\n",
        "        super().__init__()\n",
        "        self.population = num_mamls\n",
        "        self.input_dim = input_dim\n",
        "        self.support_size = support_size\n",
        "        self.query_size = query_size\n",
        "        self.herd = nn.ModuleList([\n",
        "            MAML(input_dim=self.input_dim, hidden_units=hidden_units, \n",
        "                 hidden_layers=hidden_layers, inner_lr=inner_lr) \n",
        "            for k in range(self.population)\n",
        "        ])\n",
        "    \n",
        "    def loss(self, X, Y):\n",
        "        X_support = X[:, :self.support_size ,:]\n",
        "        X_query = X[:, self.support_size:, :]\n",
        "        Y_support = Y[:, :self.support_size]\n",
        "        Y_query = Y[:, self.support_size:]\n",
        "        maml_losses = [m.loss(X_support, Y_support, X_query, Y_query) for m in self.herd]\n",
        "        return sum(maml_losses)\n",
        "    \n",
        "    def forward(self, X_train, Y_train, X_test, samples=None):\n",
        "        preds = [m.forward(X_train, Y_train, X_test) for m in self.herd]\n",
        "        Y_pred = torch.stack(preds)\n",
        "        return Y_pred.detach()\n",
        "\n",
        "\n",
        "class MAML(nn.Module):\n",
        "    '''Implementation of MAML'''\n",
        "    def __init__(self, input_dim, hidden_units, hidden_layers, inner_lr):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.net = FunctionalMLP(input_dim, hidden_units, 1, hidden_layers)\n",
        "        self.inner_lr = inner_lr\n",
        "        self.loss_func = nn.MSELoss()\n",
        "\n",
        "    def inner_loop(self, init_weights, X_support, Y_support, X_query):\n",
        "        '''Do inner update step on mini-batch of tasks with input data X and labels Y.'''\n",
        "        out = self.net(X_support, init_weights).squeeze(-1)\n",
        "        loss = self.loss_func(out, Y_support)\n",
        "        grads = torch.autograd.grad(loss, init_weights, create_graph=True)\n",
        "        temp_weights = [x - self.inner_lr * g for x, g in zip(init_weights, grads)]\n",
        "        return self.net(X_query, temp_weights).squeeze(-1)\n",
        "\n",
        "    def loss(self, X_support, Y_support, X_query, Y_query):\n",
        "        init_weights = [x for x in self.net.parameters()]\n",
        "        Y_pred = self.inner_loop(init_weights, X_support, Y_support, X_query)\n",
        "        meta_loss = self.loss_func(Y_pred, Y_query)\n",
        "        return meta_loss.mean()\n",
        "\n",
        "    def forward(self, X_train, Y_train, X_test):\n",
        "        init_weights = [x for x in self.net.parameters()]\n",
        "        Y_pred = self.inner_loop(init_weights, X_train, Y_train, X_test)\n",
        "        return Y_pred\n",
        "\n",
        "\n",
        "class Alpaca(MetaGP):\n",
        "    '''Implementation of Alpaca algorithm, viewed as Bayesian linear regression.'''\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim,\n",
        "        deep_kernel_dim=None,\n",
        "        hidden_units=None,\n",
        "        hidden_layers=None,\n",
        "    ):\n",
        "        super().__init__(input_dim, deep_kernel_dim, hidden_units, hidden_layers)\n",
        "        self.likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
        "        self.gp = LinearRegression(self.likelihood, deep_kernel_dim or 1)\n",
        "        self.mll = gpytorch.mlls.ExactMarginalLogLikelihood(self.likelihood, self.gp)\n",
        "        self.deep_kernel = (\n",
        "            MLP(input_dim, hidden_units, deep_kernel_dim, hidden_layers)\n",
        "            if deep_kernel_dim is not None\n",
        "            else None\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSorMwXvb-Bt"
      },
      "source": [
        "# Initialize Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPH-S-SsfkFH"
      },
      "source": [
        "train_size = None\n",
        "K = 5\n",
        "query_size = 5\n",
        "\n",
        "data_generator = FunctionTaskGenerator(input_dim=1, transform=atan_transform).to(device)\n",
        "input_dim = data_generator.input_dim\n",
        "\n",
        "if train_size is not None:\n",
        "    training_tasks = []\n",
        "    for _ in range(train_size):\n",
        "        task_x, task_y = data_generator(batch=batch, K=K + query_size)\n",
        "        training_tasks.append((task_x, task_y))\n",
        "\n",
        "def get_training_tasks():\n",
        "    if train_size is None:\n",
        "        while 1:\n",
        "            yield data_generator(batch=batch, K=K + query_size)\n",
        "    else:\n",
        "        while 1:\n",
        "            random.shuffle(training_tasks)\n",
        "            for task_x, task_y in training_tasks:\n",
        "                yield task_x, task_y\n",
        "\n",
        "training_generator = iter(get_training_tasks())\n",
        "\n",
        "#data_generator = FunctionTaskGenerator(\n",
        "#    input_dim=1,\n",
        "#    latent_dim=1,\n",
        "#    lengthscale=0.5,\n",
        "#    transform=csc_tranform,\n",
        "#).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw2YVjLcgOjx"
      },
      "source": [
        "#Initialize Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "oOnFANBgr4KI",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "91d1b9e6-4a86-4e07-e117-c1832f6c89b4"
      },
      "source": [
        "batch = 50\n",
        "val_interval = 1000\n",
        "val_trials = 50\n",
        "val_samples = 20\n",
        "itr = 0\n",
        "learning_rate = 1e-3\n",
        "\n",
        "model_name = 'Alpaca'\n",
        "model = {\n",
        "    'VMGP': lambda: VariationalMetaGP(\n",
        "        input_dim=input_dim,\n",
        "        hidden_units=40,\n",
        "        latent_dim=10,\n",
        "        hidden_layers=2,\n",
        "        out_var=1e-2,\n",
        "        deep_kernel_dim=10,\n",
        "    ),\n",
        "    'MGP': lambda: MetaGP(\n",
        "        input_dim=input_dim,\n",
        "        deep_kernel_dim=10,\n",
        "        hidden_units=40,\n",
        "        hidden_layers=2,\n",
        "    ),\n",
        "    'EMAML': lambda: EMAML(\n",
        "        input_dim=input_dim,\n",
        "        hidden_units=40,\n",
        "        hidden_layers=2,\n",
        "        support_size=K,\n",
        "        query_size=query_size\n",
        "    ),\n",
        "    'Alpaca': lambda: Alpaca(\n",
        "        input_dim=input_dim,\n",
        "        deep_kernel_dim=10,\n",
        "        hidden_units=40,\n",
        "        hidden_layers=2,\n",
        "    )\n",
        "}[model_name]().to(device)\n",
        "\n",
        "train_losses = []\n",
        "validation_nll = []\n",
        "validation_mse = []\n",
        "opt = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-64bb66b25a14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mhidden_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     )\n\u001b[0;32m---> 39\u001b[0;31m }[model_name]().to(device)\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-64bb66b25a14>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mdeep_kernel_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     ),\n\u001b[0;32m---> 20\u001b[0;31m     'MGP': lambda: MetaGP(\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mdeep_kernel_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MetaGP' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVrhk3c-YnAT"
      },
      "source": [
        "def print_stats():\n",
        "    if train_losses: \n",
        "        print(f'Iteration {itr} loss:', np.mean(train_losses[-val_interval:]))\n",
        "    if validation_nll: \n",
        "        print(f'Iteration {itr} nll:', validation_nll[-1])\n",
        "        print(f'Iteration {itr} mse:', validation_mse[-1])\n",
        "        print()\n",
        "\n",
        "def nll_metric(pred_y, test_y, out_var=0.1):\n",
        "    err = torch.pow(pred_y - test_y.unsqueeze(0), 2) / out_var\n",
        "    return -torch.logsumexp(-err, dim=0).mean() + np.log(pred_y.size(0))\n",
        "\n",
        "def mse_metric(pred_y, test_y):\n",
        "    return torch.pow(pred_y.mean(dim=0) - test_y, 2).mean()\n",
        "\n",
        "def validate_model(val_trials, query_size=1, out_of_range=False, return_se=False):\n",
        "    nlls = []\n",
        "    mses = []\n",
        "    for _ in range(val_trials):\n",
        "        task_x, task_y = data_generator(batch=1, K=K + query_size, validation=True)\n",
        "        train_x, train_y = task_x[0, :K], task_y[0, :K]\n",
        "        test_x, test_y = task_x[0, -query_size:], task_y[0, -query_size:]\n",
        "        pred_y = model(train_x, train_y, test_x, samples=val_samples)\n",
        "        nlls.append(nll_metric(pred_y, test_y).item())\n",
        "        mses.append(mse_metric(pred_y, test_y).item())\n",
        "    if return_se:\n",
        "        return np.mean(nlls), np.mean(mses), np.std(nlls) / np.sqrt(val_trials), np.std(mses) / np.sqrt(val_trials)\n",
        "    return np.mean(nlls), np.mean(mses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkksqZercJ6s"
      },
      "source": [
        "# Sanity Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "bkPxHRC7YNjV",
        "outputId": "feffd28d-1a8c-4815-ba54-16d4f79f3596"
      },
      "source": [
        "# Example validation task\n",
        "task_x, task_y = data_generator(batch=1, K=K + query_size + 50000)\n",
        "train_x, train_y = task_x[0, :K], task_y[0, :K]\n",
        "test_x, test_y = task_x[0, K:K+query_size], task_y[0, K:K+query_size]\n",
        "plot_x, plot_y = task_x[0, K+query_size:], task_y[0, K+query_size:]\n",
        "\n",
        "print('train_x:', train_x.tolist())\n",
        "print('train_y:', train_y.tolist())\n",
        "print('test_x:', test_x.tolist())\n",
        "print('test_y:', test_y.tolist())\n",
        "print()\n",
        "\n",
        "pred_y = model(train_x, train_y, test_x, samples=250)\n",
        "print('mu_test_y:', pred_y.mean(dim=0).tolist())\n",
        "print('sigma_test_y:', pred_y.std(dim=0).tolist())\n",
        "print()\n",
        "\n",
        "nll = nll_metric(pred_y, test_y)\n",
        "mse = mse_metric(pred_y, test_y)\n",
        "print('nll:', nll.item())\n",
        "print('mse:', mse.item())\n",
        "\n",
        "test_x_ = torch.arange(\n",
        "    task_x.min() - 1., task_x.max() + 1., 1e-1, device=device\n",
        ")[:, None].expand(-1, train_x.size(1))\n",
        "pred_y_ = model(train_x, train_y, test_x_, samples=50)\n",
        "pred_mu = pred_y_.mean(dim=0)\n",
        "pred_sigma = pred_y_.std(dim=0)\n",
        "plt.figure()\n",
        "plt.hist(pred_y[..., 0].cpu().numpy(), bins=50)\n",
        "plt.show()\n",
        "plt.figure(dpi=150)\n",
        "plt.scatter(train_x[:, 0].cpu().numpy(), train_y.cpu().numpy(), s=10, color='blue', label='training', zorder=3)\n",
        "plt.scatter(plot_x.cpu().numpy(), plot_y.cpu().numpy(), s=2, color='limegreen', label='actual', zorder=1)\n",
        "plt.plot(test_x_[:, 0].cpu().numpy(), pred_mu.cpu().numpy(), color='orange', label='prediction', zorder=2)\n",
        "plt.fill_between(\n",
        "    test_x_[:, 0].cpu().numpy(),\n",
        "    (pred_mu - pred_sigma).cpu().numpy(), \n",
        "    (pred_mu + pred_sigma).cpu().numpy(),\n",
        "    alpha=0.2,\n",
        "    color='orange',\n",
        ")\n",
        "plt.scatter(test_x[:, 0].tolist(), test_y.tolist(), s=10, color='red', label='testing', zorder=4)\n",
        "plt.ylabel('$y$')\n",
        "plt.xlabel('$x$')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f336f25734e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example validation task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtask_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mquery_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mquery_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mquery_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplot_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mquery_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mquery_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data_generator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sdcud5mccXEb"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406,
          "referenced_widgets": [
            "23e7c331c9f4424b9f0a52ddb21fda40",
            "ee31828abfa34acdbe972f40aaa31b94",
            "4aeee22b18dc46c495aca47f52a57291",
            "0068cad980e544e4a3825ecef04f61ee",
            "abdc093d3edc4071adf210adbda9c8b4",
            "b3c75824f28b49bab470f2cebce902a4",
            "3ce8ec29b49a4eb595789140192e8078",
            "8b51560feda4421394c7b52200d9d397"
          ]
        },
        "id": "USxmIzyLr4KR",
        "scrolled": true,
        "outputId": "f160c978-192c-469f-ef54-2c9a7d3910ac"
      },
      "source": [
        "for _ in tqdm.trange(10000):\n",
        "    task_x, task_y = next(training_generator)\n",
        "    if val_interval and itr % val_interval == 0:\n",
        "        nll, mse = validate_model(val_trials, query_size=query_size)\n",
        "        validation_nll.append(nll)\n",
        "        validation_mse.append(mse)\n",
        "        print_stats()\n",
        "    loss = model.loss(task_x, task_y)\n",
        "    train_losses.append(loss.item())\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    itr += 1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23e7c331c9f4424b9f0a52ddb21fda40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-861e16acd09a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtask_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mval_interval\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mitr\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mval_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mnll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_nll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-d4211d7a294e>\u001b[0m in \u001b[0;36mget_training_tasks\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mquery_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMbtqXVacpC6"
      },
      "source": [
        "#Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5S1JoWt8HgC"
      },
      "source": [
        "def smooth(data, kernel, maxnorm=np.inf):\n",
        "    return nn.functional.conv1d(\n",
        "        torch.tensor(data)[None, None, :].float().clamp(min=-maxnorm, max=maxnorm),\n",
        "        torch.ones(kernel)[None, None, :] / kernel,\n",
        "    ).flatten().numpy()\n",
        "\n",
        "results = {}\n",
        "def cache_results(name):\n",
        "    results[name] = (train_losses, validation_nll, validation_mse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQOCuPHAr4KT"
      },
      "source": [
        "plt.figure(dpi=100)\n",
        "plt.plot(smooth(train_losses, 1), linewidth=0.3)\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JhiKRuNr4KV"
      },
      "source": [
        "plt.figure(dpi=100)\n",
        "plt.plot(smooth(validation_nll, 1), linewidth=0.8)\n",
        "plt.title('Validation NLL')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('NLL')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-T5F6JEu87t"
      },
      "source": [
        "plt.figure(dpi=100)\n",
        "plt.plot(smooth(validation_mse, 1), linewidth=0.8)\n",
        "plt.title('Validation MSE')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('MSE')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45f08y7PFTw2"
      },
      "source": [
        "cache_results('mgp_sin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oASYYz5cJHny"
      },
      "source": [
        "plt.figure(dpi=100)\n",
        "start_iter = 5\n",
        "\n",
        "for k, (_, nlls, mses) in results.items():\n",
        "    plt.plot(np.arange(start_iter, len(nlls)), nlls[start_iter:], label=k)\n",
        "\n",
        "plt.ylabel('NLL')\n",
        "plt.xlabel('Iteration')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(dpi=100)\n",
        "for k, (_, nlls, mses) in results.items():\n",
        "    plt.plot(np.arange(start_iter, len(mses)), mses[start_iter:], label=k)\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Iteration')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oppByPEbW1yP",
        "outputId": "941d1abd-3707-49af-e67a-264dacd0b1b1"
      },
      "source": [
        "nll_mean, mse_mean, nll_se, mse_se = validate_model(val_trials=2000, query_size=query_size, out_of_range=False, return_se=True)\n",
        "dict(nll_mean=nll_mean, nll_se=nll_se, mse_mean=mse_mean, mse_se=mse_se)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gpytorch/utils/cholesky.py:46: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
            "  warnings.warn(f\"A not p.d., added jitter of {jitter_new:.1e} to the diagonal\", NumericalWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mse_mean': 0.6015626240206184,\n",
              " 'mse_se': 0.01294987489320119,\n",
              " 'nll_mean': 0.9142115069031715,\n",
              " 'nll_se': 0.011262755170894577}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    }
  ]
}